{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import os\n",
    "import warnings\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import keras\n",
    "import cv2\n",
    "import random\n",
    "from skimage import io,transform\n",
    "from tflearn.layers.conv import global_avg_pool\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16(input_tensor=None, input_shape=None):\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "\n",
    "    # Classification block\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    #x = Dense(4096, activation='relu', name='fca')(x)\n",
    "    #x = Dense(4096, activation='relu', name='fcb')(x)\n",
    "    x = Dense(40, activation='softmax', name='Classification')(x)\n",
    "\n",
    "    inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg16')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading(dirs = os.getcwd()):\n",
    "\n",
    "    trainMatrix = []\n",
    "    trainLabel = []\n",
    "    testMatrix = []\n",
    "    testLabel = []\n",
    "    countOfPeople = 0\n",
    "    for i in range(1, 40):\n",
    "        if i == 14:\n",
    "            continue\n",
    "        file = os.path.join(dirs, 'CroppedYale', 'yaleB%02d' % i, '*.pgm')\n",
    "    \n",
    "        rawImg = io.imread_collection(file)\n",
    "        \n",
    "        imgs = np.array([cv2.resize(img, (224,224), interpolation = cv2.INTER_CUBIC) for img in rawImg])\n",
    "        imgs = np.array(imgs, dtype=np.int64)\n",
    "        \n",
    "        countOfPeople = len(imgs)\n",
    "        \n",
    "        train = imgs[0:35]\n",
    "        trainMatrix.append(train)\n",
    "        for j in range(0, 35): trainLabel.append(i)\n",
    "            \n",
    "        test = imgs[countOfPeople-30:countOfPeople]\n",
    "        testMatrix.append(test)\n",
    "        for j in range(0, 30): testLabel.append(i) \n",
    "\n",
    "        \n",
    "    return trainMatrix, trainLabel, testMatrix, testLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainMatrix, trainLabel, testMatrix, testLabel = loading(os.getcwd())\n",
    "\n",
    "\n",
    "trainCount = np.size(trainLabel, 0)\n",
    "testCount = np.size(testLabel, 0)\n",
    "\n",
    "\n",
    "trainMatrix = np.array(trainMatrix).reshape(trainCount,224,224,1)\n",
    "\n",
    "testMatrix = np.array(testMatrix).reshape(testCount,224,224,1)\n",
    "\n",
    "\n",
    "print(\"TrainCount: %d\" % trainCount)\n",
    "print(\"TestCount: %d\\n\" % testCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabel_encode = np_utils.to_categorical(trainLabel, num_classes=40)\n",
    "testLabel_encode = np_utils.to_categorical(testLabel, num_classes=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = VGG16(input_shape=[224, 224, 1])\n",
    "sgd = SGD(lr=0.0001, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "history = model.fit(trainMatrix, trainLabel_encode, epochs=100, batch_size=32, \n",
    "                    validation_data=(testMatrix, testLabel_encode), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'], 'g', label='train_acc')\n",
    "plt.plot(history.history['val_acc'], 'b', label='val_acc')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], 'g', label='train_loss')\n",
    "plt.plot(history.history['val_loss'], 'b', label='val_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x = testMatrix, y = testLabel_encode, batch_size = 32)\n",
    "print(\"loss : \", loss)\n",
    "print(\"accuracy : \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
