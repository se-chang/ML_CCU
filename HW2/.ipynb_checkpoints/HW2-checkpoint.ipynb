{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import os\n",
    "import warnings\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import keras\n",
    "import cv2\n",
    "from skimage import io,transform\n",
    "from tflearn.layers.conv import global_avg_pool\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16(input_tensor=None, input_shape=None):\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "\n",
    "    # Classification block\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    #x = Dense(4096, activation='relu', name='fca')(x)\n",
    "    #x = Dense(4096, activation='relu', name='fcb')(x)\n",
    "    x = Dense(40, activation='softmax', name='Classification')(x)\n",
    "\n",
    "    inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg16')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading(dirs = os.getcwd()):\n",
    "\n",
    "    trainMatrix = []\n",
    "    trainLabel = []\n",
    "    testMatrix = []\n",
    "    testLabel = []\n",
    "    countOfPeople = 0\n",
    "    for i in range(1, 40):\n",
    "        if i == 14:\n",
    "            continue\n",
    "        file = os.path.join(dirs, 'CroppedYale', 'yaleB%02d' % i, '*.pgm')\n",
    "        rawImg = io.imread_collection(file)\n",
    "        \n",
    "        imgs = np.array([cv2.resize(img, (224,224), interpolation = cv2.INTER_CUBIC) for img in rawImg])\n",
    "        imgs = np.array(imgs, dtype=np.int64)\n",
    "        \n",
    "        countOfPeople = len(imgs)\n",
    "        #print(countOfPeople)\n",
    "        \n",
    "        train = imgs[0:35]\n",
    "        trainMatrix.append(train)\n",
    "        for j in range(0, 35): trainLabel.append(i)\n",
    "            \n",
    "        \n",
    "        \n",
    "        test = imgs[countOfPeople-35+1:countOfPeople]\n",
    "        testMatrix.append(test)\n",
    "        print(np.array(testMatrix).shape)\n",
    "        \n",
    "        \n",
    "        for j in range(35, countOfPeople): testLabel.append(i) \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    return trainMatrix, trainLabel, testMatrix, testLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30, 224, 224)\n",
      "(2, 30, 224, 224)\n",
      "(3, 30, 224, 224)\n",
      "(4, 30, 224, 224)\n",
      "(5, 30, 224, 224)\n",
      "(6, 30, 224, 224)\n",
      "(7, 30, 224, 224)\n",
      "(8, 30, 224, 224)\n",
      "(9, 30, 224, 224)\n",
      "(10, 30, 224, 224)\n",
      "(11,)\n",
      "(12,)\n",
      "(13,)\n",
      "(14,)\n",
      "(15,)\n",
      "(16,)\n",
      "(17,)\n",
      "(18,)\n",
      "(19,)\n",
      "(20,)\n",
      "(21,)\n",
      "(22,)\n",
      "(23,)\n",
      "(24,)\n",
      "(25,)\n",
      "(26,)\n",
      "(27,)\n",
      "(28,)\n",
      "(29,)\n",
      "(30,)\n",
      "(31,)\n",
      "(32,)\n",
      "(33,)\n",
      "(34,)\n",
      "(35,)\n",
      "(36,)\n",
      "(37,)\n",
      "(38,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 38 into shape (1122,224,224,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-0b56b6184057>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtrainMatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainMatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainCount\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtestMatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestMatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestCount\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TrainCount: %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtrainCount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 38 into shape (1122,224,224,1)"
     ]
    }
   ],
   "source": [
    "trainMatrix, trainLabel, testMatrix, testLabel = loading(os.getcwd())\n",
    "\n",
    "\n",
    "trainCount = np.size(trainLabel, 0)\n",
    "testCount = np.size(testLabel, 0)\n",
    "\n",
    "\n",
    "\n",
    "trainMatrix = np.array(trainMatrix).reshape(trainCount,224,224,1)\n",
    "testMatrix = np.array(testMatrix).reshape(testCount,224,224,1)\n",
    "\n",
    "print(\"TrainCount: %d\" % trainCount)\n",
    "print(\"TestCount: %d\\n\" % testCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "trainLabel_encode = np_utils.to_categorical(trainLabel, num_classes=40)\n",
    "testLabel_encode = np_utils.to_categorical(testLabel, num_classes=40)\n",
    "print(trainLabel_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 224, 224, 1)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      640       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "Classification (Dense)       (None, 40)                1003560   \n",
      "=================================================================\n",
      "Total params: 15,717,096\n",
      "Trainable params: 15,717,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "1330/1330 [==============================] - 38s 28ms/step - loss: 3.6888 - acc: 0.0271\n",
      "Epoch 2/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6887 - acc: 0.0263\n",
      "Epoch 3/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6886 - acc: 0.0286\n",
      "Epoch 4/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6884 - acc: 0.0338\n",
      "Epoch 5/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6883 - acc: 0.0308\n",
      "Epoch 6/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6882 - acc: 0.0293\n",
      "Epoch 7/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6880 - acc: 0.0353\n",
      "Epoch 8/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6879 - acc: 0.0308\n",
      "Epoch 9/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6878 - acc: 0.0331\n",
      "Epoch 10/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6876 - acc: 0.0271\n",
      "Epoch 11/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6875 - acc: 0.0316\n",
      "Epoch 12/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6874 - acc: 0.0278\n",
      "Epoch 13/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6872 - acc: 0.0286\n",
      "Epoch 14/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6871 - acc: 0.0308\n",
      "Epoch 15/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6870 - acc: 0.0316\n",
      "Epoch 16/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6868 - acc: 0.0263\n",
      "Epoch 17/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6867 - acc: 0.0293\n",
      "Epoch 18/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6866 - acc: 0.0263\n",
      "Epoch 19/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6864 - acc: 0.0286\n",
      "Epoch 20/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6863 - acc: 0.0271\n",
      "Epoch 21/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6862 - acc: 0.0271\n",
      "Epoch 22/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6860 - acc: 0.0271\n",
      "Epoch 23/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6859 - acc: 0.0271\n",
      "Epoch 24/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6858 - acc: 0.0278\n",
      "Epoch 25/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6856 - acc: 0.0271\n",
      "Epoch 26/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6855 - acc: 0.0278\n",
      "Epoch 27/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6854 - acc: 0.0271\n",
      "Epoch 28/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6852 - acc: 0.0271\n",
      "Epoch 29/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6851 - acc: 0.0271\n",
      "Epoch 30/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6849 - acc: 0.0263\n",
      "Epoch 31/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6848 - acc: 0.0263\n",
      "Epoch 32/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6847 - acc: 0.0263\n",
      "Epoch 33/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6845 - acc: 0.0263\n",
      "Epoch 34/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6844 - acc: 0.0308\n",
      "Epoch 35/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6842 - acc: 0.0286\n",
      "Epoch 36/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6841 - acc: 0.0301\n",
      "Epoch 37/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6839 - acc: 0.0271\n",
      "Epoch 38/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6838 - acc: 0.0293\n",
      "Epoch 39/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6836 - acc: 0.0316\n",
      "Epoch 40/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6835 - acc: 0.0278\n",
      "Epoch 41/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6833 - acc: 0.0286\n",
      "Epoch 42/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6832 - acc: 0.0263\n",
      "Epoch 43/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6830 - acc: 0.0271\n",
      "Epoch 44/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6828 - acc: 0.0278\n",
      "Epoch 45/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6827 - acc: 0.0278\n",
      "Epoch 46/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6825 - acc: 0.0286\n",
      "Epoch 47/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6824 - acc: 0.0271\n",
      "Epoch 48/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6822 - acc: 0.0271\n",
      "Epoch 49/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6820 - acc: 0.0271\n",
      "Epoch 50/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6819 - acc: 0.0286\n",
      "Epoch 51/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6817 - acc: 0.0271\n",
      "Epoch 52/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6815 - acc: 0.0278\n",
      "Epoch 53/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6813 - acc: 0.0286\n",
      "Epoch 54/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6812 - acc: 0.0286\n",
      "Epoch 55/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6810 - acc: 0.0293\n",
      "Epoch 56/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6808 - acc: 0.0293\n",
      "Epoch 57/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6806 - acc: 0.0286\n",
      "Epoch 58/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6804 - acc: 0.0286\n",
      "Epoch 59/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6803 - acc: 0.0286\n",
      "Epoch 60/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6801 - acc: 0.0271\n",
      "Epoch 61/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6799 - acc: 0.0271\n",
      "Epoch 62/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6797 - acc: 0.0263\n",
      "Epoch 63/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6795 - acc: 0.0286\n",
      "Epoch 64/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6793 - acc: 0.0271\n",
      "Epoch 65/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6791 - acc: 0.0271\n",
      "Epoch 66/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6789 - acc: 0.0271\n",
      "Epoch 67/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6787 - acc: 0.0263\n",
      "Epoch 68/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6785 - acc: 0.0263\n",
      "Epoch 69/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6783 - acc: 0.0271\n",
      "Epoch 70/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6780 - acc: 0.0271\n",
      "Epoch 71/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6778 - acc: 0.0271\n",
      "Epoch 72/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6776 - acc: 0.0278\n",
      "Epoch 73/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6774 - acc: 0.0271\n",
      "Epoch 74/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6771 - acc: 0.0271\n",
      "Epoch 75/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6769 - acc: 0.0278\n",
      "Epoch 76/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6767 - acc: 0.0271\n",
      "Epoch 77/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6765 - acc: 0.0271\n",
      "Epoch 78/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6762 - acc: 0.0271\n",
      "Epoch 79/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6760 - acc: 0.0278\n",
      "Epoch 80/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6757 - acc: 0.0263\n",
      "Epoch 81/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6755 - acc: 0.0271\n",
      "Epoch 82/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6753 - acc: 0.0263\n",
      "Epoch 83/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6750 - acc: 0.0263\n",
      "Epoch 84/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6748 - acc: 0.0263\n",
      "Epoch 85/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6745 - acc: 0.0271\n",
      "Epoch 86/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6742 - acc: 0.0278\n",
      "Epoch 87/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6740 - acc: 0.0278\n",
      "Epoch 88/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6737 - acc: 0.0278\n",
      "Epoch 89/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6735 - acc: 0.0286\n",
      "Epoch 90/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6732 - acc: 0.0278\n",
      "Epoch 91/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6729 - acc: 0.0271\n",
      "Epoch 92/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6726 - acc: 0.0263\n",
      "Epoch 93/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6724 - acc: 0.0263\n",
      "Epoch 94/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6721 - acc: 0.0271\n",
      "Epoch 95/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6718 - acc: 0.0263\n",
      "Epoch 96/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6715 - acc: 0.0278\n",
      "Epoch 97/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6712 - acc: 0.0278\n",
      "Epoch 98/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6709 - acc: 0.0271\n",
      "Epoch 99/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6706 - acc: 0.0263\n",
      "Epoch 100/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6703 - acc: 0.0263\n",
      "Epoch 101/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6700 - acc: 0.0263\n",
      "Epoch 102/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6697 - acc: 0.0286\n",
      "Epoch 103/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6694 - acc: 0.0263\n",
      "Epoch 104/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6691 - acc: 0.0271\n",
      "Epoch 105/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6688 - acc: 0.0263\n",
      "Epoch 106/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6685 - acc: 0.0263\n",
      "Epoch 107/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6682 - acc: 0.0263\n",
      "Epoch 108/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6679 - acc: 0.0263\n",
      "Epoch 109/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6676 - acc: 0.0263\n",
      "Epoch 110/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6673 - acc: 0.0278\n",
      "Epoch 111/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6670 - acc: 0.0263\n",
      "Epoch 112/300\n",
      "1330/1330 [==============================] - 37s 28ms/step - loss: 3.6666 - acc: 0.0263\n",
      "Epoch 113/300\n",
      "1330/1330 [==============================] - 37s 28ms/step - loss: 3.6663 - acc: 0.0263\n",
      "Epoch 114/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6660 - acc: 0.0263\n",
      "Epoch 115/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6657 - acc: 0.0263\n",
      "Epoch 116/300\n",
      "1330/1330 [==============================] - 37s 27ms/step - loss: 3.6653 - acc: 0.0263\n",
      "Epoch 117/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6650 - acc: 0.0271\n",
      "Epoch 118/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6647 - acc: 0.0263\n",
      "Epoch 119/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6644 - acc: 0.0271\n",
      "Epoch 120/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6640 - acc: 0.0263\n",
      "Epoch 121/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6637 - acc: 0.0271\n",
      "Epoch 122/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6634 - acc: 0.0263\n",
      "Epoch 123/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6630 - acc: 0.0263\n",
      "Epoch 124/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6627 - acc: 0.0271\n",
      "Epoch 125/300\n",
      "1330/1330 [==============================] - 37s 27ms/step - loss: 3.6624 - acc: 0.0263\n",
      "Epoch 126/300\n",
      "1330/1330 [==============================] - 37s 27ms/step - loss: 3.6620 - acc: 0.0263\n",
      "Epoch 127/300\n",
      "1330/1330 [==============================] - 37s 28ms/step - loss: 3.6617 - acc: 0.0263\n",
      "Epoch 128/300\n",
      "1330/1330 [==============================] - 37s 28ms/step - loss: 3.6614 - acc: 0.0271\n",
      "Epoch 129/300\n",
      "1330/1330 [==============================] - 37s 28ms/step - loss: 3.6611 - acc: 0.0263\n",
      "Epoch 130/300\n",
      "1330/1330 [==============================] - 37s 28ms/step - loss: 3.6607 - acc: 0.0263\n",
      "Epoch 131/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6604 - acc: 0.0293\n",
      "Epoch 132/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6601 - acc: 0.0271\n",
      "Epoch 133/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6598 - acc: 0.0293\n",
      "Epoch 134/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6594 - acc: 0.0263\n",
      "Epoch 135/300\n",
      "1330/1330 [==============================] - 37s 27ms/step - loss: 3.6591 - acc: 0.0293\n",
      "Epoch 136/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6588 - acc: 0.0263\n",
      "Epoch 137/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6584 - acc: 0.0263\n",
      "Epoch 138/300\n",
      "1330/1330 [==============================] - 37s 28ms/step - loss: 3.6581 - acc: 0.0263\n",
      "Epoch 139/300\n",
      "1330/1330 [==============================] - 37s 27ms/step - loss: 3.6578 - acc: 0.0263\n",
      "Epoch 140/300\n",
      "1330/1330 [==============================] - 37s 28ms/step - loss: 3.6575 - acc: 0.0263\n",
      "Epoch 141/300\n",
      "1330/1330 [==============================] - 37s 28ms/step - loss: 3.6572 - acc: 0.0263\n",
      "Epoch 142/300\n",
      "1330/1330 [==============================] - 37s 28ms/step - loss: 3.6568 - acc: 0.0263\n",
      "Epoch 143/300\n",
      "1330/1330 [==============================] - 37s 28ms/step - loss: 3.6566 - acc: 0.0271\n",
      "Epoch 144/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6562 - acc: 0.0271\n",
      "Epoch 145/300\n",
      "1330/1330 [==============================] - 37s 28ms/step - loss: 3.6559 - acc: 0.0271\n",
      "Epoch 146/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6557 - acc: 0.0263\n",
      "Epoch 147/300\n",
      "1330/1330 [==============================] - 37s 27ms/step - loss: 3.6554 - acc: 0.0263\n",
      "Epoch 148/300\n",
      "1330/1330 [==============================] - 37s 28ms/step - loss: 3.6550 - acc: 0.0263\n",
      "Epoch 149/300\n",
      "1330/1330 [==============================] - 37s 28ms/step - loss: 3.6547 - acc: 0.0271\n",
      "Epoch 150/300\n",
      "1330/1330 [==============================] - 37s 28ms/step - loss: 3.6545 - acc: 0.0263\n",
      "Epoch 151/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6542 - acc: 0.0301\n",
      "Epoch 152/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6539 - acc: 0.0301\n",
      "Epoch 153/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6536 - acc: 0.0323\n",
      "Epoch 154/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6533 - acc: 0.0286\n",
      "Epoch 155/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6531 - acc: 0.0286\n",
      "Epoch 156/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6528 - acc: 0.0278\n",
      "Epoch 157/300\n",
      "1330/1330 [==============================] - 37s 27ms/step - loss: 3.6525 - acc: 0.0271\n",
      "Epoch 158/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6522 - acc: 0.0211\n",
      "Epoch 159/300\n",
      "1330/1330 [==============================] - 37s 28ms/step - loss: 3.6520 - acc: 0.0233\n",
      "Epoch 160/300\n",
      "1330/1330 [==============================] - 101s 76ms/step - loss: 3.6517 - acc: 0.0361\n",
      "Epoch 161/300\n",
      "1330/1330 [==============================] - 87s 66ms/step - loss: 3.6515 - acc: 0.0346\n",
      "Epoch 162/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6512 - acc: 0.0338\n",
      "Epoch 163/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6510 - acc: 0.0286\n",
      "Epoch 164/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6507 - acc: 0.0293\n",
      "Epoch 165/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6505 - acc: 0.0346\n",
      "Epoch 166/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6503 - acc: 0.0323\n",
      "Epoch 167/300\n",
      "1330/1330 [==============================] - 36s 27ms/step - loss: 3.6500 - acc: 0.0293\n",
      "Epoch 168/300\n",
      "1330/1330 [==============================] - 37s 27ms/step - loss: 3.6498 - acc: 0.0323\n",
      "Epoch 169/300\n",
      " 480/1330 [=========>....................] - ETA: 23s - loss: 3.6485 - acc: 0.0375"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-d578915c457b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainMatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLabel_encode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ML2018\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ML2018\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ML2018\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ML2018\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ML2018\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ML2018\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ML2018\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ML2018\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ML2018\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = VGG16(input_shape=[224, 224, 1])\n",
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model.summary()\n",
    "history = model.fit(trainMatrix, trainLabel_encode, epochs=300, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1122/1122 [==============================] - 10s 9ms/step\n",
      "loss :  6.082103450455555\n",
      "accuracy :  0.08021390374331551\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x = testMatrix, y = testLabel_encode, batch_size = 32)\n",
    "print(\"loss : \", score[0])\n",
    "print(\"accuracy : \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
